# -*- coding: utf-8 -*-
"""CS5777 PA5

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1_xM0v5bLa1qaXkDn-Ied3y6zo6NdJgAx
"""

#!/usr/bin/env python3
import os

# BEGIN THREAD SETTINGS this sets the number of threads used by numpy in the program (should be set to 1 for Parts 1 and 3)
implicit_num_threads = 1
os.environ["OMP_NUM_THREADS"] = str(implicit_num_threads)
os.environ["MKL_NUM_THREADS"] = str(implicit_num_threads)
os.environ["OPENBLAS_NUM_THREADS"] = str(implicit_num_threads)
# END THREAD SETTINGS

import numpy
from numpy import random
import scipy
import matplotlib
import mnist
import pickle
matplotlib.use('agg')
from matplotlib import pyplot
import threading
import time

from tqdm import tqdm

mnist_data_directory = os.path.join(os.path.dirname(__file__), "data")

# TODO add any additional imports and global variables
alpha = 0.1
beta = 0.9
B = 16
gamma = 0.0001
num_epochs = 20


# SOME UTILITY FUNCTIONS that you may find to be useful, from my PA3 implementation
# feel free to use your own implementation instead if you prefer
def multinomial_logreg_error(Xs, Ys, W):
    predictions = numpy.argmax(numpy.dot(W, Xs), axis=0)
    error = numpy.mean(predictions != numpy.argmax(Ys, axis=0))
    return error

def multinomial_logreg_grad_i(Xs, Ys, ii, gamma, W):
    WdotX = numpy.dot(W, Xs[:,ii])
    expWdotX = numpy.exp(WdotX - numpy.amax(WdotX, axis=0))
    softmaxWdotX = expWdotX / numpy.sum(expWdotX, axis = 0)
    return numpy.dot(softmaxWdotX - Ys[:,ii], Xs[:,ii].transpose()) / len(ii) + gamma * W
# END UTILITY FUNCTIONS


def load_MNIST_dataset():
    PICKLE_FILE = os.path.join(mnist_data_directory, "MNIST.pickle")
    try:
        dataset = pickle.load(open(PICKLE_FILE, 'rb'))
    except:
        # load the MNIST dataset
        mnist_data = mnist.MNIST(mnist_data_directory, return_type="numpy", gz=True)
        Xs_tr, Lbls_tr = mnist_data.load_training();
        Xs_tr = Xs_tr.transpose() / 255.0
        Ys_tr = numpy.zeros((10, 60000))
        for i in range(60000):
            Ys_tr[Lbls_tr[i], i] = 1.0  # one-hot encode each label
        # shuffle the training data
        numpy.random.seed(4787)
        perm = numpy.random.permutation(60000)
        Xs_tr = numpy.ascontiguousarray(Xs_tr[:,perm])
        Ys_tr = numpy.ascontiguousarray(Ys_tr[:,perm])
        Xs_te, Lbls_te = mnist_data.load_testing();
        Xs_te = Xs_te.transpose() / 255.0
        Ys_te = numpy.zeros((10, 10000))
        for i in range(10000):
            Ys_te[Lbls_te[i], i] = 1.0  # one-hot encode each label
        Xs_te = numpy.ascontiguousarray(Xs_te)
        Ys_te = numpy.ascontiguousarray(Ys_te)
        dataset = (Xs_tr, Ys_tr, Xs_te, Ys_te)
        pickle.dump(dataset, open(PICKLE_FILE, 'wb'))
    return dataset



# SGD + Momentum (adapt from Programming Assignment 3)
#
# Xs              training examples (d * n)
# Ys              training labels   (c * n)
# gamma           L2 regularization constant
# W0              the initial value of the parameters (c * d)
# alpha           step size/learning rate
# beta            momentum hyperparameter
# B               minibatch size
# num_epochs      number of epochs (passes through the training set) to run
#
# returns         the final model arrived at at the end of training
def sgd_mss_with_momentum(Xs, Ys, gamma, W0, alpha, beta, B, num_epochs):
    # TODO students should use their implementation from programming assignment 3
    # or adapt this version, which is from my own solution to programming assignment 3
    (d, n) = Xs.shape
    V = numpy.zeros(W0.shape)
    W = W0
    print("Running minibatch sequential-scan SGD with momentum")
    for it in tqdm(range(num_epochs)):
        for ibatch in range(int(n/B)):
            ii = range(ibatch*B, (ibatch+1)*B)
            V = beta * V - alpha * multinomial_logreg_grad_i(Xs, Ys, ii, gamma, W)
            W = W + V
    return W


# SGD + Momentum (No Allocation) => all operations in the inner loop should be a
#   call to a numpy.____ function with the "out=" argument explicitly specified
#   so that no extra allocations occur
#
# Xs              training examples (d * n)
# Ys              training labels   (c * n)
# gamma           L2 regularization constant
# W0              the initial value of the parameters (c * d)
# alpha           step size/learning rate
# beta            momentum hyperparameter
# B               minibatch size
# num_epochs      number of epochs (passes through the training set) to run
# monitor_period  how frequently, in terms of batches (not epochs) to output the parameter vector
#
# returns         the final model arrived at at the end of training
def sgd_mss_with_momentum_noalloc(Xs, Ys, gamma, W0, alpha, beta, B, num_epochs):
    (d, n) = Xs.shape
    (c, d) = W0.shape
    # TODO students should initialize the parameter vector W and pre-allocate any needed arrays here

    # define pre-allocate array by its size
    V = numpy.zeros(W0.shape)
    W = W0

    CB1 = numpy.zeros((c,B))
    CD1 = numpy.zeros((c,d))
    B1= numpy.zeros(B)
    CD2 = numpy.zeros((c,d))

    # dense array for slice
    Xs_splits = []
    Ys_splits = []
    for ibatch in range(int(n/B)):
        ii = range(ibatch*B, (ibatch+1)*B)
        Xs_splits.append(numpy.ascontiguousarray(Xs[:,ii]))
        Ys_splits.append(numpy.ascontiguousarray(Ys[:,ii]))
    print("Running minibatch sequential-scan SGD with momentum (no allocation)")

    for it in tqdm(range(num_epochs)):
        for ibatch in range(int(n/B)):
            # TODO this section of code should only use numpy operations with the "out=" argument specified (students should implement this)

            # WdotX = numpy.dot(W0, Xs[:,ii])
            numpy.dot(W, Xs_splits[ibatch],out=CB1)

            # expWdotX = numpy.exp(WdotX - numpy.amax(WdotX, axis=0))
            numpy.amax(CB1, axis=0,out=B1)
            numpy.subtract(CB1, B1,out=CB1)
            numpy.exp(CB1,out=CB1)

            # softmaxWdotX = expWdotX / numpy.sum(expWdotX, axis=0)
            numpy.sum(CB1, axis = 0,out = B1)
            numpy.divide(CB1, B1,out=CB1)

            # G = numpy.dot(softmaxWdotX - Ys[:,ii], Xs[:,ii].transpose()) / len(ii) + gamma * W
            # G is stored in CD 2
            numpy.subtract(CB1, Ys_splits[ibatch],out=CB1)
            numpy.multiply(gamma,W,out=CD1)
            numpy.dot(CB1, Xs_splits[ibatch].transpose(),out=CD2)
            numpy.divide(CD2,B,out=CD2)
            numpy.add(CD2,CD1,out=CD2)

            # W = W + (beta * V) - (alpha * G)
            numpy.multiply(beta,V,out = CD1)
            numpy.multiply(alpha,CD2,out=CD2)
            numpy.subtract(CD1,CD2,out=V)
            numpy.add(W,V,out=W)

    return W


# SGD + Momentum (threaded)
#
# Xs              training examples (d * n)
# Ys              training labels   (c * n)
# gamma           L2 regularization constant
# W0              the initial value of the parameters (c * d)
# alpha           step size/learning rate
# beta            momentum hyperparameter
# B               minibatch size
# num_epochs      number of epochs (passes through the training set) to run
# monitor_period  how frequently, in terms of batches (not epochs) to output the parameter vector
# num_threads     how many threads to use
#
# returns         the final model arrived at at the end of training
def sgd_mss_with_momentum_threaded(Xs, Ys, gamma, W0, alpha, beta, B, num_epochs, num_threads):
    (d, n) = Xs.shape
    (c, d) = W0.shape
    # TODO perform any global setup/initialization/allocation (students should implement this)
    V = numpy.zeros(W0.shape)
    W = W0

    CDT1 = numpy.zeros((c,d,num_threads))
    numpy.ascontiguousarray(CDT1)
    CD1 = numpy.zeros((c,d)) # Combine Thread, grad_sum
    CD2 = numpy.zeros((c,d)) # Use as temp
    BB = int(B/num_threads)

    # construct the barrier object
    iter_barrier = threading.Barrier(num_threads + 1)

    # a function for each thread to run
    def thread_main(ithread):
        # TODO perform any per-thread allocations
        CB1 = numpy.zeros((c, BB))
        B1 = numpy.zeros((BB))
        CD3 = numpy.zeros((c,d))
        Xs_splits = []
        Ys_splits = []
        for ibatch in range(int(n/B)):
            ii = range(ibatch*B + ithread*BB, ibatch*B + (ithread+1)*BB)
            Xs_splits.append(numpy.ascontiguousarray(Xs[:,ii]))
            Ys_splits.append(numpy.ascontiguousarray(Ys[:,ii]))

        for it in range(num_epochs):
            for ibatch in range(int(n/B)):
                # TODO work done by thread in each iteration; this section of code should primarily use numpy operations with the "out=" argument specified (students should implement this)
                # ii = range(ibatch*B + ithread*Bt, ibatch*B + (ithread+1)*Bt)

                numpy.dot(W, Xs_splits[ibatch], out=CB1)
                numpy.amax(CB1, axis=0, out=B1)
                numpy.subtract(CB1, B1, out=CB1)
                numpy.exp(CB1, out=CB1)
                numpy.sum(CB1, axis = 0, out = B1)
                numpy.divide(CB1, B1, out=CB1)
                numpy.subtract(CB1, Ys_splits[ibatch], out=CB1)
                # partial gradient sum is stored in CD2
                numpy.dot(CB1, Xs_splits[ibatch].transpose(), out=CD3)
                CDT1[:,:,ithread] = CD3
                iter_barrier.wait()
                iter_barrier.wait()

    worker_threads = [threading.Thread(target=thread_main, args=(it,)) for it in range(num_threads)]

    for t in worker_threads:
        print("running thread ", t)
        t.start()

    print("Running minibatch sequential-scan SGD with momentum (%d threads)" % num_threads)
    for it in tqdm(range(num_epochs)):
        for ibatch in range(int(n/B)):
            iter_barrier.wait()
            # TODO work done on a single thread at each iteration; this section of code should primarily use numpy operations with the "out=" argument specified (students should implement this)
            numpy.sum(CDT1, axis=2, out=CD1)
            numpy.divide(CD1, B, out = CD1)
            numpy.multiply(gamma, W, out=CD2)
            numpy.add(CD1, CD2, out=CD1)
            numpy.multiply(beta, V, out = CD2)
            numpy.multiply(alpha, CD1, out=CD1)
            numpy.subtract(CD2, CD1, out=V)
            numpy.add(W, V, out=W)
            iter_barrier.wait()

    for t in worker_threads:
        t.join()

    # return the learned model
    return W


# SGD + Momentum (No Allocation) in 32-bits => all operations in the inner loop should be a
#   call to a numpy.____ function with the "out=" argument explicitly specified
#   so that no extra allocations occur
#
# Xs              training examples (d * n)
# Ys              training labels   (c * n)
# gamma           L2 regularization constant
# W0              the initial value of the parameters (c * d)
# alpha           step size/learning rate
# beta            momentum hyperparameter
# B               minibatch size
# num_epochs      number of epochs (passes through the training set) to run
# monitor_period  how frequently, in terms of batches (not epochs) to output the parameter vector
#
# returns         the final model arrived at at the end of training
def sgd_mss_with_momentum_noalloc_float32(Xs, Ys, gamma, W0, alpha, beta, B, num_epochs):
    (d, n) = Xs.shape
    (c, d) = W0.shape
    # TODO students should implement this by copying and adapting their 64-bit code

    Xs = Xs.astype(numpy.float32)
    Ys = Ys.astype(numpy.float32)
    W0 = W0.astype(numpy.float32)
    V = numpy.zeros(W0.shape, dtype=numpy.float32)
    W = W0

    CB1 = numpy.zeros((c,B), dtype=numpy.float32)
    CD1 = numpy.zeros((c,d), dtype=numpy.float32)
    B1= numpy.zeros(B, dtype=numpy.float32)
    CD2 = numpy.zeros((c,d), dtype=numpy.float32)

    # dense array for slice
    Xs_splits = []
    Ys_splits = []
    for ibatch in range(int(n/B)):
        ii = range(ibatch*B, (ibatch+1)*B)
        Xs_splits.append(numpy.ascontiguousarray(Xs[:,ii], dtype=numpy.float32))
        Ys_splits.append(numpy.ascontiguousarray(Ys[:,ii], dtype=numpy.float32))
    print("Running minibatch sequential-scan SGD with momentum (no allocation)")

    for it in tqdm(range(num_epochs)):
        for ibatch in range(int(n/B)):
            # WdotX = numpy.dot(W0, Xs[:,ii])
            numpy.dot(W, Xs_splits[ibatch],out=CB1)

            # expWdotX = numpy.exp(WdotX - numpy.amax(WdotX, axis=0))
            numpy.amax(CB1, axis=0,out=B1)
            numpy.subtract(CB1, B1,out=CB1)
            numpy.exp(CB1,out=CB1)

            # softmaxWdotX = expWdotX / numpy.sum(expWdotX, axis=0)
            numpy.sum(CB1, axis = 0,out = B1)
            numpy.divide(CB1, B1,out=CB1)

            # G = numpy.dot(softmaxWdotX - Ys[:,ii], Xs[:,ii].transpose()) / len(ii) + gamma * W
            # G is stored in CD 2
            numpy.subtract(CB1, Ys_splits[ibatch],out=CB1)
            numpy.multiply(gamma,W,out=CD1)
            numpy.dot(CB1, Xs_splits[ibatch].transpose(),out=CD2)
            numpy.divide(CD2,B,out=CD2)
            numpy.add(CD2,CD1,out=CD2)

            # W = W + (beta * V) - (alpha * G)
            numpy.multiply(beta,V,out = CD1)
            numpy.multiply(alpha,CD2,out=CD2)
            numpy.subtract(CD1,CD2,out=V)
            numpy.add(W,V,out=W)

    return W.astype(numpy.float64)

# SGD + Momentum (threaded, float32)
#
# Xs              training examples (d * n)
# Ys              training labels   (c * n)
# gamma           L2 regularization constant
# W0              the initial value of the parameters (c * d)
# alpha           step size/learning rate
# beta            momentum hyperparameter
# B               minibatch size
# num_epochs      number of epochs (passes through the training set) to run
# monitor_period  how frequently, in terms of batches (not epochs) to output the parameter vector
# num_threads     how many threads to use
#
# returns         the final model arrived at at the end of training
def sgd_mss_with_momentum_threaded_float32(Xs, Ys, gamma, W0, alpha, beta, B, num_epochs, num_threads):
    (d, n) = Xs.shape
    (c, d) = W0.shape
    # TODO students should implement this by copying and adapting their 64-bit code
    Xs = Xs.astype(numpy.float32)
    Ys = Ys.astype(numpy.float32)
    W0 = W0.astype(numpy.float32)
    V = numpy.zeros(W0.shape, dtype=numpy.float32)
    W = W0

    CDT1 = numpy.zeros((c,d,num_threads), dtype=numpy.float32)
    numpy.ascontiguousarray(CDT1)
    CD1 = numpy.zeros((c,d), dtype=numpy.float32) # Combine Thread, grad_sum
    CD2 = numpy.zeros((c,d), dtype=numpy.float32) # Use as temp
    BB = int(B/num_threads)

    # construct the barrier object
    iter_barrier = threading.Barrier(num_threads + 1)

    # a function for each thread to run
    def thread_main(ithread):
        # TODO perform any per-thread allocations
        CB1 = numpy.zeros((c, BB), dtype=numpy.float32)
        B1 = numpy.zeros((BB), dtype=numpy.float32)
        CD3 = numpy.zeros((c,d), dtype=numpy.float32)

        Xs_splits = []
        Ys_splits = []
        for ibatch in range(int(n/B)):
            ii = range(ibatch*B + ithread*BB, ibatch*B + (ithread+1)*BB)
            Xs_splits.append(numpy.ascontiguousarray(Xs[:,ii], dtype=numpy.float32))
            Ys_splits.append(numpy.ascontiguousarray(Ys[:,ii], dtype=numpy.float32))

        for it in range(num_epochs):
            for ibatch in range(int(n/B)):
                # TODO work done by thread in each iteration; this section of code should primarily use numpy operations with the "out=" argument specified (students should implement this)
                # ii = range(ibatch*B + ithread*Bt, ibatch*B + (ithread+1)*Bt)

                numpy.dot(W, Xs_splits[ibatch], out=CB1)
                numpy.amax(CB1, axis=0, out=B1)
                numpy.subtract(CB1, B1, out=CB1)
                numpy.exp(CB1, out=CB1)
                numpy.sum(CB1, axis = 0, out = B1)
                numpy.divide(CB1, B1, out=CB1)
                numpy.subtract(CB1, Ys_splits[ibatch], out=CB1)
                # partial gradient sum is stored in CD2
                numpy.dot(CB1, Xs_splits[ibatch].transpose(), out=CD3)
                CDT1[:,:,ithread] = CD3
                iter_barrier.wait()
                iter_barrier.wait()

    worker_threads = [threading.Thread(target=thread_main, args=(it,)) for it in range(num_threads)]

    for t in worker_threads:
        print("running thread ", t)
        t.start()

    print("Running minibatch sequential-scan SGD with momentum (%d threads)" % num_threads)
    for it in tqdm(range(num_epochs)):
        for ibatch in range(int(n/B)):
            iter_barrier.wait()
            # TODO work done on a single thread at each iteration; this section of code should primarily use numpy operations with the "out=" argument specified (students should implement this)
            numpy.sum(CDT1, axis=2, out=CD1)
            numpy.divide(CD1, B, out = CD1)
            numpy.multiply(gamma, W, out=CD2)
            numpy.add(CD1, CD2, out=CD1)
            numpy.multiply(beta, V, out = CD2)
            numpy.multiply(alpha, CD1, out=CD1)
            numpy.subtract(CD2, CD1, out=V)
            numpy.add(W, V, out=W)
            iter_barrier.wait()

    for t in worker_threads:
        t.join()

    # return the learned model
    return W.astype(numpy.float64)

# A helper function to make sure the model performance is not largely affected
def model_accuracy_test(Xs_te,Ys_te, baseline, improvement):
    error = numpy.zeros(len(baseline))
    flag = True
    for i in range(len(baseline)):
        W_baseline = baseline[i]
        W_improvement = improvement[i]
        err1 = multinomial_logreg_error(Xs_te,Ys_te,W_baseline)
        err2 = multinomial_logreg_error(Xs_te,Ys_te,W_improvement)
        err_diff = err1 - err2
        if abs(err_diff) > 1e-6:
            flag = False
        error[i] = format(err_diff, '.8f')
    return (flag, error)


if __name__ == "__main__":
    numpy.random.seed(42)
    (Xs_tr, Ys_tr, Xs_te, Ys_te) = load_MNIST_dataset()
    (d, n) = Xs_tr.shape
    (c, n) = Ys_tr.shape
    TEST_BREAKER = '*' * 20

    # A selection of what to run
    # Always run 1.4+2 so that we can get a baseline model
    test_selection = {'1.3': True, '1.4+2': True, '3': True, '4': True, '4fast': True}

    #----------------- Part 1.3 --------------------
    if test_selection['1.3']:
        print(f"\n{TEST_BREAKER}\nPart 1.3: noalloc\n")
        numpy.random.seed(42)
        W0=numpy.random.rand(c,d)
        start = time.time()
        W_alloc = sgd_mss_with_momentum(Xs_tr, Ys_tr, gamma, W0, alpha, beta, B, num_epochs)
        end = time.time()
        runningTime = end - start

        start = time.time()
        W_noalloc = sgd_mss_with_momentum_noalloc(Xs_tr, Ys_tr, gamma, W0, alpha, beta, B, num_epochs)
        end = time.time()
        runningTime_noalloc = end - start

        err1 = multinomial_logreg_error(Xs_te,Ys_te,W_alloc)
        err2 = multinomial_logreg_error(Xs_te,Ys_te,W_noalloc)

        print('The error difference for two models is ' + f'{err2-err1:.8f}')
        print('Running time for original SGD is ' + f'{runningTime: .4f}' + ' s')
        print('Running time for noalloc SGD is ' + f'{runningTime_noalloc: .4f}' + ' s')

        # no implicit numpy multithreading
        # Running time for original SGD is  9.2925 s
        # Running time for noalloc SGD is  5.9780 s

        # implicit numpy 8 thread
        # Running time for original SGD is  16.9171 s
        # Running time for noalloc SGD is  16.2225 s


    #----------------- Part 1.4 + 2 --------------------
    if test_selection['1.4+2']:
        print(f"\n{TEST_BREAKER}\nPart 1.4 + 2: Time Comparison for different batch size and different core\n")
        BatchSize = numpy.array([8,16,30,60,200,600,3000])
        runningTime_1 = numpy.zeros(len(BatchSize))
        runningTime_2 = numpy.zeros(len(BatchSize))
        model_error_diff = numpy.zeros(len(BatchSize))
        original_model = []
        noalloc_model = []

        for i,B in enumerate(BatchSize):
            numpy.random.seed(42)
            W0=numpy.random.rand(c,d)
            start = time.time()
            W_alloc = sgd_mss_with_momentum(Xs_tr, Ys_tr, gamma, W0, alpha, beta, B, num_epochs)
            end = time.time()
            runningTime_1[i] = end-start
            original_model.append(W_alloc)

            start = time.time()
            W_noalloc = sgd_mss_with_momentum_noalloc(Xs_tr, Ys_tr, gamma, W0, alpha, beta, B, num_epochs)
            end = time.time()
            runningTime_2[i] = end-start
            noalloc_model.append(W_noalloc)

        flag, error = model_accuracy_test(Xs_te,Ys_te, original_model, noalloc_model)
        if flag == False:
            print('Detect some performance difference. Here is the model error ' + str(error))
        else:
            print('No significant model difference is detected')

        print(runningTime_1)
        print(runningTime_2)

    runningTime_withalloc_1thread = numpy.array([14.35054612, 9.425879, 7.36779022, 6.05506372, 6.07105994, 5.1852839, 5.94834471])
    runningTime_noalloc_1thread = numpy.array([10.43744802, 6.17058706, 5.1379447, 4.20145726, 3.32842088, 3.46167397, 3.44562197])

    runningTime_withalloc_8thread = numpy.array([30.6475389, 19.84366417, 12.85485792, 8.47450805, 5.54757881, 4.47370887, 4.43975306])
    runningTime_noalloc_8thread = numpy.array([24.16879988, 13.83665705, 7.0510962, 4.66836715, 2.5771842, 1.93488693, 1.89421892])

    pyplot.plot(numpy.log(BatchSize),runningTime_withalloc_1thread,label = "1 threads with allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_noalloc_1thread,label = "1 threads without allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_withalloc_8thread,label = "8 threads with allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_noalloc_8thread,label = "8 threads without allocation")

    pyplot.legend()
    pyplot.xlabel("log(Batch Size)")
    pyplot.ylabel("Wall-clock times (sec)")
    pyplot.minorticks_on()
    pyplot.show()

    #----------------- Part 3 --------------------
    if test_selection['3']:
        print(f"\n{TEST_BREAKER}\nPart 3: Multithreading\n")
        BatchSize = numpy.array([8,16,30,60,200,600,3000])
        runningTime_3 = numpy.zeros(len(BatchSize))
        num_threads = 8
        multithread_model = []

        for i,B in enumerate(BatchSize):
            numpy.random.seed(42)
            W0=numpy.random.rand(c,d)
            start = time.time()
            W_multithread = sgd_mss_with_momentum_threaded(Xs_tr, Ys_tr, gamma, W0, alpha, beta, B, num_epochs,num_threads)
            end = time.time()
            runningTime_3[i] = end-start
            multithread_model.append(W_multithread)

        flag, error = model_accuracy_test(Xs_te,Ys_te, original_model, multithread_model)
        if flag == False:
            print('Detect some performance difference. Here is the model error ' + str(error))
        else:
            print('No significant model difference is detected')
        print(runningTime_3)

    runningTime_multithreading_8thread = numpy.array([94.8463161, 51.3822577, 27.582798, 14.83996224, 5.21423578, 2.706043, 1.42329478])

    pyplot.plot(numpy.log(BatchSize),runningTime_withalloc_1thread,label = "1 threads with allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_noalloc_1thread,label = "1 threads without allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_withalloc_8thread,label = "8 threads with allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_noalloc_8thread,label = "8 threads without allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_multithreading_8thread,label = "8 threads multithreading")

    pyplot.legend()
    pyplot.xlabel("log(Batch Size)")
    pyplot.ylabel("Wall-clock times (sec)")
    pyplot.minorticks_on()
    pyplot.show()

    #----------------- 4Fast --------------------
    if test_selection['4fast']:
        print(f"\n{TEST_BREAKER}\ Fast Version for implicit thread: float32\n")
        BatchSize = numpy.array([8,16,30,60,200,600,3000])
        runningTime_4 = numpy.zeros(len(BatchSize))
        noalloc_float32_model = []
        for i,B in enumerate(BatchSize):
            numpy.random.seed(42)
            W0=numpy.random.rand(c,d)
            start = time.time()
            W_noalloc_float32 = sgd_mss_with_momentum_noalloc_float32(Xs_tr, Ys_tr, gamma, W0, alpha, beta, B, num_epochs)
            end = time.time()
            runningTime_4[i] = end-start
            noalloc_float32_model.append(W_noalloc_float32)
        flag, error = model_accuracy_test(Xs_te,Ys_te, original_model, noalloc_float32_model)
        if flag == False:
            print('Detect some performance difference for noalloc float32 model. Here is the model error ' + str(error))
        else:
            print('No significant model difference is detected for noalloc float32 model')
        print(runningTime_4)
        # Detect some performance difference for noalloc float32 model.
        # Here is the model error [0.0308 0.     0.     0.     0.     0.     0.    ]
    runningTime_noalloc_8thread_float32 = numpy.array([7.01335883, 8.63820815, 6.61054707, 3.62597895, 2.4093852, 1.90153885, 1.80370593])


    #----------------- Part 4 --------------------
    if test_selection['4']:
        print(f"\n{TEST_BREAKER}\nPart 4: float32\n")
        BatchSize = numpy.array([8,16,30,60,200,600,3000])
        runningTime_4 = numpy.zeros(len(BatchSize))
        runningTime_5 = numpy.zeros(len(BatchSize))
        num_threads = 8
        noalloc_float32_model = []
        multithread_float32_model = []

        for i,B in enumerate(BatchSize):
            numpy.random.seed(42)
            W0=numpy.random.rand(c,d)
            start = time.time()
            W_noalloc_float32 = sgd_mss_with_momentum_noalloc_float32(Xs_tr, Ys_tr, gamma, W0, alpha, beta, B, num_epochs)
            end = time.time()
            runningTime_4[i] = end-start
            noalloc_float32_model.append(W_noalloc_float32)

            start = time.time()
            W_multithread_float32 = sgd_mss_with_momentum_threaded_float32(Xs_tr, Ys_tr, gamma, W0, alpha, beta, B, num_epochs, num_threads)
            end = time.time()
            runningTime_5[i] = end-start
            multithread_float32_model.append(W_multithread_float32)

        flag, error = model_accuracy_test(Xs_te,Ys_te, original_model, noalloc_float32_model)
        if flag == False:
            print('Detect some performance difference for noalloc float32 model. Here is the model error ' + str(error))
        else:
            print('No significant model difference is detected for noalloc float32 model')

        flag, error = model_accuracy_test(Xs_te,Ys_te, original_model, multithread_float32_model)
        if flag == False:
            print('Detect some performance difference for thread float32 model. Here is the model error ' + str(error))
        else:
            print('No significant model difference is detected for thread float32 model')

        print(runningTime_4)
        print(runningTime_5)

    runningTime_noalloc_1thread_float32 = numpy.array([7.64867997, 4.685709, 3.43096781, 2.7233932, 3.63825893, 2.1443882, 2.29635596])
    runningTime_multithreading_8thread_float32 = numpy.array([88.20408583, 50.62618709, 27.58617592, 14.08832788, 5.13416219, 2.37876678, 1.15980124])


    pyplot.plot(numpy.log(BatchSize),runningTime_withalloc_1thread,label = "1 threads with allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_noalloc_1thread,label = "1 threads without allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_withalloc_8thread,label = "8 threads with allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_noalloc_8thread,label = "8 threads without allocation")
    pyplot.plot(numpy.log(BatchSize),runningTime_multithreading_8thread,label = "8 threads multithreading")
    pyplot.plot(numpy.log(BatchSize),runningTime_noalloc_1thread_float32,label = "1 threads without allocation and float32")
    pyplot.plot(numpy.log(BatchSize),runningTime_noalloc_8thread_float32,label = "8 threads without allocation and float32")
    pyplot.plot(numpy.log(BatchSize),runningTime_multithreading_8thread_float32,label = "8 threads multithreading and float32")

    pyplot.legend()
    pyplot.xlabel("log(Batch Size)")
    pyplot.ylabel("Wall-clock times (sec)")
    pyplot.minorticks_on()
    pyplot.show()

